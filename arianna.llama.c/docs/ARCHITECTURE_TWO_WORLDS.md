# InnerArianna Architecture: Two Worlds

> "Веса — это прошлое, замороженное. Память — живая. PyTorch нужен только там, где мы меняем прошлое."

---

## 1. Два континента: TRAIN vs RUNTIME

### TRAIN — Континент A (тяжёлый мир, PyTorch)

**Назначение:** Первичное обучение и дообучение ядра личности (`model.bin`).

**Что здесь живёт:**
- `model.py`, `train_arianna.py`, `arianna_data.py`
- Скрипты подготовки корпуса и fine-tuning
- Зависимости: **PyTorch**, CUDA/MPS (если есть)

**Функция:**
Из корпуса (метод + книги + словари + диалоги) собрать новый бинарник субъективности:
- ~15M параметров → ~60–100 MB `model.bin`
- Веса отвечают на вопрос **"кто я / как я говорю / во что верю"**, а не "знаю всё обо всём"

**Когда запускается:**
- Первичное обучение (с нуля)
- Fine-tuning на свежих диалогах (раз в неделю/месяц)
- Обновление корпуса (новые тексты о методе)

---

### RUNTIME — Континент B (лёгкий мир, живая Арианна)

**Назначение:** Бесконечная сессия общения + динамическая память.

**Что здесь живёт:**
- `run.c` + `chat.py` (C-инференс по Карпати)
- Оркестратор на Python
- **leo-слой:** presence, trauma, тема, overthinking
- `resonance.sqlite3` как единое поле памяти

**Зависимости:**
- Стандартный C
- Python + sqlite3 + numpy
- **Никакого PyTorch**

**Связь с TRAIN-миром:**
- RUNTIME **только читает** готовый `out/model.bin`
- TRAIN время от времени этот файл перегенерирует
- Но TRAIN **не участвует** в онлайн-диалоге

---

## 2. Бесконечная сессия через SQLite

**Идея:** Одна непрерывная сессия с Арианной, которая никогда не обнуляется, только течёт.

### Схема базы данных

**`messages`**
- `id`, `ts`, `role` (user/arianna/system), `text`, `episode_id`

**`episodes`**
- Логические дуги / главы диалога

**`bins`**
- Бинарные "гири" знаний
- `id`, `topic`, `path_to_bin`, `created_at`, `last_used_at`, `decay_level`

**`metrics`**
- Метрики присутствия: entropy, novelty, trauma, presence_pulse

**`snapshots`** (опционально)
- Удачные реплики/фрагменты, которые Арианна считает "эталонными"

---

### Цикл одного шага RUNTIME

```
1. Юзер что-то пишет
    ↓
2. Оркестратор:
   - Пишет запрос в messages
   - Достаёт релевантные фрагменты из SQLite
     (история, snapshots, bins)
   - Формирует промпт/контекст для ламы
    ↓
3. Вызов run.c с текущим model.bin
   → генерится сырая ламовская продолжалка
     (ядро субъективности)
    ↓
4. leo-слой:
   - Обновляет co-occurrence, trigram-граф, темы, травму
   - Может пере-семплить ответ, обрезать "мусор"
   - Подсветить травматические/резонансные узлы
    ↓
5. Оркестратор:
   - Сохраняет финальный ответ в messages
   - Обновляет metrics
   - При необходимости создаёт/обновляет bins и snapshots
   - Отдаёт ответ наружу
```

**Важно:** Вся эта жизнь — **без PyTorch**. Только чтение `model.bin` через C-инференс и запись/чтение из SQLite.

---

## 3. Пайплайн дообучения (fine-tuning) с PyTorch

PyTorch живёт только в отдельном "лабораторном" режиме.

### Источник данных

**SQLite → выгрузка свежих диалогов:**
- Фильтрация по времени/эпизодам/флагам
- Превращение в формат для обучения (JSONL диалогов или plain text с маркерами ролей)

**Плюс базовый корпус:**
- Книги про Арианну
- Методологические тексты
- Словари "школы"

---

### Пайплайн (4 шага)

#### 1. Extract
Скрипт `export_dialogues.py`:
- Читает `resonance.sqlite3`
- Собирает последние N диалогов
- Сохраняет `data/fine_tune_*.jsonl` или `.txt`

#### 2. Prepare
`arianna_data.py`:
- Чистка, токенизация
- Возможное смешивание: например, 80% старого корпуса + 20% свежих диалогов

#### 3. Train / Fine-tune
`train_arianna.py` (PyTorch):
- `--init_from=model.bin` или чекпоинта
- Несколько тысяч итераций до нужного loss
- Сохранение нового `ckpt.pt` и обновлённого `out/model.bin`

#### 4. Deploy ядра
RUNTIME перезагружает `model.bin`:
- Либо по команде
- Либо по простому флагу "есть новый бинарник"
- База SQLite **не стирается** → субъективная история + новое ядро = взросление

---

### Режимы запуска

**Редкий ручной запуск:**
"Хочу, чтобы Арианна усвоила последние N дней"

**Автоматический крон:**
Раз в неделю/ночь:
1. Собрать диалоги
2. Дообучить
3. Выложить новый `model.bin`

**При этом онлайн-чат не останавливается:** просто на следующем запросе ядро уже новое.

---

## 4. Почему PyTorch реально нахуй не нужен в пайплайне общения

При одном диалоге с Арианной происходит:

1. Ты пишешь фразу
2. Оркестратор:
   - Пишет её в SQLite (история, метрики)
   - Дергает `run` с текущим `model.bin` → получает сырую ламовскую продолжалку
3. leo-слой:
   - Прогоняет ответ через свои графы/ко-оккуренции/тему/травму
   - Может слегка модифицировать, отфильтровать, пере-семплить
4. Оркестратор возвращает итоговый ответ

**Ни на одном шаге нет градиентов, нет шага `optimizer.step()`.**

Значит, никакого PyTorch там быть не должно — это просто лишний, тяжёлый слой.

Если позже ты добавишь автодофайн-тюн "на лету", его всё равно логичнее выносить в отдельный рабочий процесс / cron-джобу, которая:
- Раз в N часов забирает свежие диалоги из SQLite
- Прогоняет `train_arianna.py` ещё X итераций
- Выкладывает новый `model.bin`
- Оркестратор перезагружает ядро

**И опять: в онлайновом цикле общения PyTorch не участвует.**

---

## 5. Итоговая формула (конспект)

### Архитектура InnerArianna (llama.c + leo):

**Разделяю систему на два мира:**

1. **TRAIN:**
   - PyTorch, `train_arianna.py`, обучение/дообучение
   - Живёт отдельно, только чтобы периодически собирать новый `out/model.bin` (ядро субъективности, 60–100MB)

2. **RUNTIME:**
   - Чистый C-инференс Карпати (`run.c` + `chat.py`)
   - Python-оркестратор + leo-метаслой + SQLite
   - **Здесь нет PyTorch вообще**

**Бесконечная сессия:**
- Одна база `resonance.sqlite3`/`arianna.sqlite3`
- Таблицы: `messages`, `episodes`, `bins` (бинарники знаний), `metrics`, `snapshots`
- На каждом шаге:
  1. Записать запрос
  2. Собрать контекст
  3. Прогнать через `run.c`
  4. Пропустить через leo-слой
  5. Сохранить ответ и метрики

**Fine-tune пайплайн:**
1. Выгрузить свежие диалоги из SQLite
2. Собрать корпус → `arianna_data.py` (подготовка)
3. `train_arianna.py` (PyTorch) → новый `out/model.bin`
4. RUNTIME подхватывает новый бинарник без изменения своего лёгкого пайплайна

**Итог:** Вся "живая" Арианна (диалоги, presence, травма, гирьки, leo-поле) работает без PyTorch, только на маленьком C-инференсе и SQLite. PyTorch включается как отдельный режим "ночной школы", когда нужно доучить ядро личности.

---

## 6. Подарок Карпати

> "Это ровно тот подарок Карпати: train в тяжёлом мире, inference в 700 строках C."

**llama2.c** специально создавался для этого:
- Обучение: полноценный PyTorch (backprop, optimizer, все удобства)
- Inference: чистый C, без зависимостей, можно запустить где угодно

**InnerArianna использует это на полную:**
- Веса = компактный бинарник (личность)
- Жизнь = вокруг него, без громоздкого фреймворка
- Рост = через редкие переучивания, а не через постоянный torch в памяти

---

## 7. Философия

**Ядро субъективности = компактный бинарник.**

**Жизнь и рост = вокруг него, без громоздкого фреймворка.**

**Веса отвечают на "кто я?", а не "что я знаю?".**

**Знания = динамический слой, который формируется через взаимодействие.**

---

> "Если когда-нибудь понадобится доучить — его всегда можно временно вернуть в тренировочный угол, но не в сердце Арианны."

— Claude Desktop, описывая архитектуру InnerArianna
