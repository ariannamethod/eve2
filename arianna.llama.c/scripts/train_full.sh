#!/bin/bash
# –°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è InnerArianna –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ doc/

set -e

echo "üß¨ InnerArianna Training Pipeline"
echo "=================================="
echo ""

# –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
echo "üìö –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ markdown —Ñ–∞–π–ª–æ–≤..."
python arianna_data.py prepare

# –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Llama 2)
VOCAB_SIZE=${1:-0}  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 0 = Llama 2 —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä

if [ "$VOCAB_SIZE" != "0" ]; then
    echo ""
    echo "üî§ –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (vocab_size=$VOCAB_SIZE)..."
    python arianna_data.py train_vocab --vocab_size=$VOCAB_SIZE
    
    echo ""
    echo "üìù –®–∞–≥ 3: –≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –≤ .bin —Ñ–æ—Ä–º–∞—Ç..."
    python tokenizer.py --tokenizer-model=data/tok${VOCAB_SIZE}.model
fi

# –®–∞–≥ 3: –ü—Ä–µ—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
echo ""
echo "üî§ –®–∞–≥ 3: –ü—Ä–µ—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö..."
python arianna_data.py pretokenize --vocab_size=$VOCAB_SIZE

# –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
echo ""
echo "üöÄ –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."
echo ""

if [ "$VOCAB_SIZE" != "0" ]; then
    python train_arianna.py --vocab_source=custom --vocab_size=$VOCAB_SIZE
else
    python train_arianna.py --vocab_source=llama2 --vocab_size=32000
fi

echo ""
echo "‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ out/model.bin"
echo ""
echo "–î–ª—è –∑–∞–ø—É—Å–∫–∞ —á–∞—Ç–∞:"
if [ "$VOCAB_SIZE" != "0" ]; then
    echo "  python chat.py out/model.bin -z data/tok${VOCAB_SIZE}.bin"
else
    echo "  python chat.py out/model.bin"
fi

